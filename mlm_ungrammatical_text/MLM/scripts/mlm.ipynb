{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[37]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertModel\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import collections\n",
    "import numpy as np\n",
    "from transformers import default_data_collator\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from cleantext import clean\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "tokenizer.add_tokens(['[newtoken]'])\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.embeddings\n",
    "weights = model.embeddings.word_embeddings.weight.data\n",
    "new_weights = torch.cat((weights, weights[101:102]), 0)\n",
    "new_emb = nn.Embedding.from_pretrained(new_weights, padding_idx=0, freeze=False)\n",
    "model.embeddings.word_embeddings = new_emb\n",
    "# out = model(**tokenized)\n",
    "# out.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0274,  0.1791,  0.1523,  ..., -0.1584,  0.0354, -0.0444],\n",
      "         [-0.6960,  0.1104,  0.3584,  ..., -0.6668,  0.2324,  0.2303],\n",
      "         [-0.2654, -0.3319,  0.3805,  ..., -0.2777,  0.2147,  0.5890],\n",
      "         ...,\n",
      "         [ 0.0858,  0.1314,  0.3512,  ...,  0.2032,  0.1003, -0.2070],\n",
      "         [ 0.4891,  0.2349, -0.1398,  ..., -0.0130, -0.6823, -0.5180],\n",
      "         [-0.2253,  0.2052,  0.6377,  ...,  0.0757,  0.1264,  0.2063]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-7.3057e-01, -1.2503e-01,  7.7696e-01,  4.5089e-01, -5.5410e-01,\n",
      "         -7.6048e-02,  7.9892e-01,  1.4670e-01,  4.8023e-01, -9.9576e-01,\n",
      "          3.0687e-01, -3.5654e-01,  9.3325e-01, -4.2645e-01,  8.4121e-01,\n",
      "         -3.2695e-01,  7.4204e-02, -4.0540e-01,  2.6838e-01, -6.6087e-01,\n",
      "          3.7474e-01, -4.3680e-01,  6.5816e-01,  1.4990e-01,  2.2884e-01,\n",
      "         -5.1004e-01, -3.0322e-01,  8.4384e-01,  8.6487e-01,  4.9512e-01,\n",
      "         -5.3456e-01,  1.2063e-01, -9.2663e-01, -1.2940e-01,  7.8965e-01,\n",
      "         -9.0039e-01, -1.6585e-02, -6.0756e-01,  2.1918e-02,  5.2327e-02,\n",
      "         -7.6534e-01,  1.3986e-01,  8.9664e-01, -4.3905e-01, -2.8360e-01,\n",
      "         -2.8289e-01, -9.7194e-01,  1.3984e-01, -6.9273e-01, -6.7866e-01,\n",
      "         -5.8823e-01, -8.0829e-01,  6.2225e-02,  1.9263e-01,  2.0405e-01,\n",
      "          5.1462e-01, -1.5121e-01,  8.8074e-02,  6.9286e-03, -3.5747e-01,\n",
      "         -4.5826e-01,  7.6880e-02,  4.8476e-01, -7.5933e-01, -6.8639e-01,\n",
      "         -7.4802e-01, -2.6452e-02, -1.1741e-01,  4.9508e-03, -1.7133e-02,\n",
      "          7.3489e-01,  1.0546e-01,  3.1210e-01, -6.2585e-01, -6.1155e-01,\n",
      "          3.1719e-02, -1.7727e-01,  9.9551e-01, -1.3900e-01, -9.0149e-01,\n",
      "         -6.7283e-01, -4.8422e-01,  1.0257e-01,  6.9711e-01, -6.6546e-01,\n",
      "         -9.8829e-01,  1.2983e-01, -3.6585e-03, -9.4991e-01,  1.2963e-01,\n",
      "          8.4762e-02, -1.2122e-01, -7.1811e-01,  1.0542e-01,  2.4669e-02,\n",
      "          6.6353e-02, -1.5675e-01,  7.1598e-01, -7.7974e-03,  2.1901e-01,\n",
      "         -1.8993e-02, -1.4944e-01,  1.5465e-01, -1.7250e-01, -1.0164e-02,\n",
      "         -1.6213e-01, -2.8472e-01,  1.4859e-02, -2.3722e-01,  4.6243e-01,\n",
      "          1.1258e-01, -1.3996e-01,  4.8307e-02, -8.8136e-01,  4.5321e-01,\n",
      "         -8.5445e-02, -9.1787e-01, -1.8210e-01, -9.3563e-01,  4.2703e-01,\n",
      "          1.7837e-01,  1.6930e-02,  8.9269e-01,  6.7037e-01,  1.2720e-01,\n",
      "          8.8236e-02,  6.8278e-01, -9.9720e-01, -7.0705e-02,  1.6002e-01,\n",
      "          3.0645e-01,  3.3888e-02, -8.9666e-01, -8.2954e-01,  3.5094e-01,\n",
      "          8.8376e-01,  3.5937e-02,  8.9187e-01, -1.0049e-01,  7.6838e-01,\n",
      "          2.3647e-01,  2.5717e-01, -4.9430e-01, -2.4223e-01, -5.8250e-02,\n",
      "          2.7825e-01, -5.0111e-01,  1.4082e-01,  2.7153e-01, -1.7125e-01,\n",
      "          3.0555e-01, -1.6624e-01,  6.0774e-01, -8.3231e-01, -3.1126e-01,\n",
      "          8.1808e-01,  4.5292e-01,  7.6067e-01,  7.2389e-01, -1.0455e-01,\n",
      "         -2.3321e-01,  6.4660e-01, -5.5101e-03,  2.0160e-01,  6.9045e-02,\n",
      "          1.9822e-01, -2.9327e-01,  2.8819e-01, -7.0486e-01,  2.1788e-01,\n",
      "          1.8966e-01, -5.8549e-02,  7.5362e-01, -8.9474e-01, -1.4387e-01,\n",
      "          2.7368e-01,  9.3836e-01,  5.8637e-01,  6.4099e-02, -2.0579e-01,\n",
      "         -1.0078e-01,  5.2572e-02, -7.9123e-01,  8.9090e-01, -5.5352e-02,\n",
      "          1.8170e-01,  6.8862e-01, -3.0031e-01, -6.8875e-01, -5.1409e-01,\n",
      "          7.0554e-01,  9.6990e-02, -6.5988e-01,  1.3177e-01, -2.8454e-01,\n",
      "         -2.5988e-01,  5.6234e-01,  2.6092e-01, -1.4868e-01, -3.0027e-01,\n",
      "          6.1965e-02,  8.1824e-01,  8.9444e-01,  6.3702e-01, -6.6572e-01,\n",
      "          2.7191e-01, -7.8762e-01, -1.6740e-01,  5.7761e-02,  1.3881e-01,\n",
      "         -1.4857e-02,  9.6511e-01,  3.0575e-01, -4.6759e-02, -8.0983e-01,\n",
      "         -9.2689e-01, -2.4238e-02, -7.4379e-01,  9.1986e-02, -4.7181e-01,\n",
      "         -2.6456e-02,  6.7785e-01, -2.0545e-01,  2.5000e-01, -9.3476e-01,\n",
      "         -6.2330e-01,  1.9927e-01,  2.4761e-02,  1.9541e-01, -1.4729e-01,\n",
      "          9.3855e-02, -7.2924e-01, -3.5528e-01,  7.1943e-01,  6.7894e-01,\n",
      "          8.0912e-01, -4.2858e-01,  6.6733e-01, -1.3580e-01,  7.3337e-01,\n",
      "         -4.1122e-01,  8.1344e-01, -5.8848e-01,  1.6943e-01, -8.0268e-01,\n",
      "          6.6822e-01, -7.9437e-01,  4.7299e-01, -1.0035e-02, -7.1106e-01,\n",
      "         -5.8349e-01,  1.3356e-01,  1.2067e-01,  8.3573e-01, -2.3586e-01,\n",
      "          9.8043e-01, -1.3930e-01, -8.2024e-01,  5.3177e-01, -1.4742e-02,\n",
      "         -9.1091e-01, -5.5761e-01,  1.1193e-01, -7.2989e-01, -1.5158e-01,\n",
      "         -1.6844e-01, -8.2019e-01,  7.4921e-01,  8.8737e-02,  9.3827e-01,\n",
      "          2.4703e-01, -7.8405e-01, -8.4893e-02, -6.8003e-01, -2.0984e-01,\n",
      "          4.4904e-02,  7.2209e-01, -1.8350e-01, -8.7043e-01,  2.5322e-01,\n",
      "          3.6050e-01,  2.3973e-01,  8.1976e-01,  9.7286e-01,  6.4487e-01,\n",
      "          9.0533e-01,  7.4415e-01,  7.9701e-01,  5.0734e-01,  1.2209e-01,\n",
      "          9.9810e-01,  4.9550e-01, -9.6512e-01, -8.3760e-01, -3.8769e-01,\n",
      "          2.6975e-01, -9.9655e-01, -2.1473e-02,  4.5909e-02, -7.5478e-01,\n",
      "         -6.1868e-01,  9.1582e-01,  9.5426e-01, -9.9265e-01,  6.9367e-01,\n",
      "          8.5083e-01, -2.0926e-01, -3.3855e-01,  3.3796e-02,  9.0569e-01,\n",
      "          1.4385e-01,  2.2467e-01, -8.0132e-02,  1.0578e-01,  6.1158e-01,\n",
      "         -6.4924e-01,  6.2578e-01,  6.9399e-01, -6.3702e-01,  1.5294e-02,\n",
      "         -4.3075e-01, -8.1842e-01, -4.6225e-01, -5.9937e-02, -3.5957e-01,\n",
      "         -8.5856e-01, -2.3941e-02, -4.9698e-01,  3.2297e-01, -2.3839e-02,\n",
      "          4.4248e-02, -6.6001e-01,  6.1639e-02, -7.7794e-01,  2.7649e-01,\n",
      "          2.7120e-01, -8.1994e-01, -4.1444e-01,  9.1488e-02, -4.5748e-01,\n",
      "          5.2173e-01, -8.2304e-01,  8.9828e-01, -1.3982e-01, -5.1544e-01,\n",
      "          9.9363e-01, -4.8043e-01, -6.9313e-01,  2.5751e-02,  1.0174e-02,\n",
      "          8.6674e-02,  9.9180e-01, -8.2116e-02, -8.9836e-01, -1.6019e-01,\n",
      "         -1.4453e-01, -1.6086e-01, -6.7064e-02,  9.7210e-01, -6.1106e-02,\n",
      "          5.6413e-01,  5.5079e-01,  8.2612e-01, -9.3296e-01, -7.6263e-01,\n",
      "         -8.1743e-01, -8.7386e-01,  8.6628e-01,  8.0692e-01,  2.2249e-01,\n",
      "         -2.8513e-01, -6.9461e-03,  3.4547e-01,  7.0485e-02, -9.1096e-01,\n",
      "          3.4544e-01,  2.7100e-01, -7.5413e-02,  7.8399e-01, -7.3361e-01,\n",
      "         -1.5093e-01,  3.0145e-01,  4.2627e-01,  4.0710e-01, -7.4179e-01,\n",
      "          2.5034e-01, -8.0269e-02,  7.3245e-02, -1.3348e-01,  1.3913e-01,\n",
      "         -9.1295e-01, -3.1382e-01,  9.8728e-01,  1.6561e-01, -7.5595e-01,\n",
      "         -5.1819e-02, -1.1444e-02, -3.4340e-01,  9.7309e-02,  2.0669e-01,\n",
      "         -1.3693e-01, -6.7492e-01, -5.2271e-01, -8.2074e-01, -9.0844e-01,\n",
      "          5.2830e-01,  7.4657e-02, -1.9405e-01,  9.1242e-01, -3.7681e-02,\n",
      "         -3.1796e-03, -2.7592e-01, -6.0065e-01, -2.2007e-02,  4.6158e-01,\n",
      "         -7.4200e-01,  8.7938e-01, -1.2749e-01,  9.5652e-02,  6.8750e-01,\n",
      "          6.9073e-01, -1.7151e-01, -4.4796e-01, -4.6506e-03, -7.4174e-01,\n",
      "          7.9381e-02, -8.2547e-01,  8.5315e-01, -8.2306e-01,  1.4021e-01,\n",
      "          4.0139e-03, -4.9706e-01,  9.9228e-01,  3.6917e-01,  3.9030e-01,\n",
      "         -5.2498e-01,  7.3580e-01,  5.5399e-01, -5.0227e-01, -2.1531e-01,\n",
      "          1.1123e-01,  7.3044e-01, -9.4580e-02,  8.9236e-02, -8.8008e-01,\n",
      "         -6.2857e-01, -5.0376e-01, -9.3260e-01, -9.4996e-01,  6.8353e-01,\n",
      "          5.3963e-01,  3.5744e-02,  5.5207e-01, -4.6765e-01, -3.7651e-01,\n",
      "         -1.9982e-04, -1.8030e-02, -8.2750e-01,  6.4502e-01, -1.3108e-01,\n",
      "          2.8445e-01, -1.3629e-01,  1.5178e-01, -7.3926e-01,  7.5704e-01,\n",
      "          8.2422e-01,  2.3026e-01,  3.4847e-02, -5.7395e-01,  6.1330e-01,\n",
      "         -6.2490e-01,  6.2233e-01, -3.2157e-02,  9.9672e-01, -1.1054e-01,\n",
      "         -6.1179e-01,  5.0394e-01,  5.2004e-01,  8.5869e-02,  7.8103e-02,\n",
      "         -7.7326e-01,  3.8844e-03,  6.9784e-01,  7.4491e-01, -7.1977e-01,\n",
      "         -1.3721e-01,  2.5361e-01, -7.2203e-01, -6.6375e-01,  5.4765e-01,\n",
      "         -2.3210e-01, -4.0317e-02,  5.1075e-02,  3.4296e-03,  9.8949e-01,\n",
      "         -5.6172e-02, -2.1959e-02, -3.1379e-01,  1.3280e-01, -1.8502e-01,\n",
      "         -5.3641e-01,  9.7036e-01,  2.2665e-01, -3.7411e-01, -9.3685e-01,\n",
      "          5.9500e-01, -7.8555e-01,  4.3331e-01,  5.0841e-01, -6.8278e-01,\n",
      "          1.3973e-01,  3.2876e-02, -2.3006e-02,  6.1312e-01, -4.2138e-02,\n",
      "         -1.7640e-01,  4.6848e-02,  9.8935e-02,  8.6488e-01, -2.1352e-01,\n",
      "         -8.4146e-01, -3.4530e-01,  1.3898e-01, -8.7668e-01, -4.7706e-01,\n",
      "         -3.0209e-01, -1.2381e-02, -5.8807e-02,  3.7687e-01,  7.8513e-01,\n",
      "         -1.0691e-01, -9.0813e-01, -7.0498e-02, -1.6042e-01,  8.6505e-01,\n",
      "          3.9561e-02, -1.4723e-01, -7.8014e-01, -7.5557e-01, -5.0868e-01,\n",
      "          7.4841e-01, -8.2859e-01,  8.8946e-01, -9.3670e-01,  1.8741e-01,\n",
      "          9.8109e-01,  1.2857e-01, -7.3794e-01,  6.5485e-02, -2.2798e-01,\n",
      "          9.9448e-02,  5.1923e-01,  2.8702e-01, -8.5989e-01, -1.2035e-01,\n",
      "         -4.4799e-02,  7.8931e-02, -6.4779e-02,  5.9646e-01,  4.4791e-01,\n",
      "          1.0069e-01, -9.0013e-02, -3.3672e-01,  1.7199e-02,  2.5515e-01,\n",
      "          4.1851e-01, -1.8775e-01,  4.0772e-03,  1.5016e-02, -7.2008e-02,\n",
      "         -7.6554e-01, -5.4972e-02, -2.0148e-03,  1.0152e-01,  4.5701e-01,\n",
      "         -9.9462e-01, -6.1883e-01, -6.1161e-01, -1.4625e-01,  6.1962e-01,\n",
      "         -1.4300e-02, -3.9237e-01, -4.8096e-01,  6.5046e-01,  8.2235e-01,\n",
      "          4.5729e-01,  2.4391e-02,  3.1084e-01, -4.3941e-01, -1.2211e-02,\n",
      "         -2.8759e-02,  1.6207e-01,  3.8643e-01,  5.6596e-01, -8.3476e-02,\n",
      "          9.9677e-01, -2.2131e-03, -1.7826e-01, -9.0431e-01,  1.5109e-01,\n",
      "         -3.7464e-02,  8.0215e-01, -7.9352e-01, -8.0683e-01,  1.5489e-01,\n",
      "         -1.0627e-01, -6.1858e-01,  9.9430e-02, -5.9414e-02, -3.7402e-01,\n",
      "          6.4577e-01,  8.9642e-01,  7.5389e-01, -1.6858e-01,  1.3929e-01,\n",
      "         -1.7449e-01, -2.1454e-01, -5.4403e-02, -7.7825e-01,  9.3852e-01,\n",
      "          9.3596e-02,  7.3539e-01,  6.2796e-01,  2.5509e-01,  8.6186e-01,\n",
      "          3.4742e-02,  4.5219e-01, -2.6876e-02,  9.7910e-01,  1.1031e-01,\n",
      "         -8.0934e-01,  5.4104e-01, -9.5391e-01, -5.3225e-02, -8.6267e-01,\n",
      "          1.3395e-01, -3.9408e-02,  6.8204e-01, -1.5130e-01,  8.4656e-01,\n",
      "          7.2505e-01,  8.9594e-02,  3.9467e-01,  7.4540e-01,  1.9630e-01,\n",
      "         -7.6630e-01, -9.3279e-01, -9.3452e-01, -1.5949e-02, -2.8045e-01,\n",
      "          1.9276e-02,  1.9355e-01,  6.5754e-02,  1.7093e-01,  2.1218e-01,\n",
      "         -9.5688e-01,  7.7360e-01,  1.8058e-01, -7.1823e-01,  8.7286e-01,\n",
      "         -3.3181e-02, -2.2730e-02,  6.6894e-02, -9.3550e-01, -8.9044e-01,\n",
      "         -1.6928e-01, -1.6340e-01,  5.7138e-01,  3.8159e-01,  6.5924e-01,\n",
      "          1.5410e-01, -3.7908e-01, -1.4224e-02,  6.0059e-01, -1.0312e-01,\n",
      "         -9.5437e-01,  2.2241e-01,  5.0567e-01, -8.8808e-01,  8.5014e-01,\n",
      "         -5.6117e-01, -8.7618e-02,  6.8744e-01,  5.2589e-01,  8.4576e-01,\n",
      "          5.2334e-01,  3.0039e-01,  8.8473e-02,  3.0551e-01,  6.9865e-01,\n",
      "          8.6158e-01,  9.3965e-01,  6.4353e-01,  5.6638e-01,  5.6411e-01,\n",
      "          1.4464e-01,  1.0188e-01, -7.8349e-01, -2.4801e-03, -2.2946e-01,\n",
      "          2.4289e-01,  4.0997e-02, -2.1414e-02, -8.9099e-01,  1.5664e-02,\n",
      "          3.2276e-02,  2.2719e-01, -2.4928e-01,  2.0508e-01, -2.4061e-01,\n",
      "         -8.1066e-02, -4.6018e-01, -1.5610e-01,  2.7068e-01,  1.4613e-01,\n",
      "          7.9557e-01, -1.5954e-01,  3.0493e-02, -3.2147e-01,  1.4926e-03,\n",
      "          6.5314e-01, -7.8041e-01,  8.4109e-01,  8.0033e-02,  5.6650e-01,\n",
      "         -6.5350e-01, -1.1568e-01,  3.9166e-01, -4.6482e-01, -2.1427e-01,\n",
      "         -1.0941e-01, -5.2101e-01,  7.1374e-01,  1.0464e-01, -2.2586e-01,\n",
      "         -1.7048e-01,  4.6204e-01,  1.7073e-01, -3.0271e-01,  5.4520e-01,\n",
      "          5.5519e-01,  8.1413e-02, -1.0836e-01,  8.6502e-02,  4.7843e-02,\n",
      "         -9.5802e-01,  2.4208e-01,  4.1259e-01, -5.4313e-01,  4.2907e-01,\n",
      "         -7.3183e-01,  2.7149e-01, -9.1146e-01,  1.0699e-03, -3.3930e-01,\n",
      "         -5.9986e-01, -3.9681e-01, -4.6962e-03,  1.2631e-01,  5.3705e-01,\n",
      "         -5.8691e-01,  7.5350e-01,  4.1067e-01,  6.3125e-01,  1.7730e-01,\n",
      "          6.4916e-01, -4.8021e-01,  7.2336e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\\nmask_token_logits = token_logits[0, mask_token_index, :]\\n# Pick the [MASK] candidates with the highest logits\\ntop_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\\nfor token in top_5_tokens:\\n    print(f\"\\'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}\\'\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a great [MASK].\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "output = model(**inputs)\n",
    "print(output)\n",
    "# Find the location of [MASK] and extract its logits\n",
    "'''\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "# Pick the [MASK] candidates with the highest logits\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a new token to the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "tokenizer.tokenize(\"[CLS] Hello world, how are you?\")\n",
    "tokenizer.tokenize(\"[newtoken] Hello world, how are you?\")\n",
    "tokenizer.add_tokens(['[newtoken]'])\n",
    "tokenizer.tokenize(\"[newtoken] Hello world, how are you?\")\n",
    "tokenized = tokenizer(\"[newtoken] Hello world, how are you?\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "print(tokenized['input_ids'])\n",
    "tkn = tokenized['input_ids'][0, 0]\n",
    "print(\"First token:\", tkn)\n",
    "print(\"Decoded:\", tokenizer.decode(tkn))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a new token to bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[8]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.embeddings\n",
    "try:\n",
    "    out = model(**tokenized)\n",
    "    out.last_hidden_state\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "weights = model.embeddings.word_embeddings.weight.data\n",
    "print(weights.shape)\n",
    "new_weights = torch.cat((weights, weights[101:102]), 0)\n",
    "new_emb = nn.Embedding.from_pretrained(new_weights, padding_idx=0, freeze=False)\n",
    "new_emb\n",
    "model.embeddings.word_embeddings = new_emb\n",
    "model.embeddings\n",
    "out = model(**tokenized)\n",
    "out.last_hidden_state\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "out2 = model(\n",
    "    **tokenizer(\"[CLS] Hello world, how are you?\", add_special_tokens=False, return_tensors=\"pt\")\n",
    ")\n",
    "torch.all(out.last_hidden_state == out2.last_hidden_state)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking a pretrained model for masked language modeling<br>\n",
    "pick a model here https://huggingface.co/models?pipeline_tag=fill-mask&sort=downloads with fill-mask filter<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[17]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> DistilBERT number of parameters: 110M'\n",
      "'>>> BERT number of parameters: 110M'\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"bert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "distilbert_num_parameters = model.num_parameters() / 1_000_000\n",
    "print(f\"'>>> DistilBERT number of parameters: {round(distilbert_num_parameters)}M'\")\n",
    "print(f\"'>>> BERT number of parameters: 110M'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a great [MASK].\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "token_logits = model(**inputs).logits\n",
    "# Find the location of [MASK] and extract its logits\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "# Pick the [MASK] candidates with the highest logits\n",
    "top_5_tokens = torch.topk(mask_token_logits, 10, dim=1).indices[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> This is a great idea.'\n",
      "'>>> This is a great day.'\n",
      "'>>> This is a great place.'\n",
      "'>>> This is a great time.'\n",
      "'>>> This is a great thing.'\n",
      "'>>> This is a great opportunity.'\n",
      "'>>> This is a great feeling.'\n",
      "'>>> This is a great surprise.'\n",
      "'>>> This is a great book.'\n",
      "'>>> This is a great deal.'\n"
     ]
    }
   ],
   "source": [
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[22]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kdu/Downloads/masters/pyenv/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Found cached dataset imdb (/Users/kdu/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1afb072d32e45a1a9c41b787c173c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def clean_input(text):\n",
    "    return clean(text,\n",
    "                fix_unicode=True,               # fix various unicode errors\n",
    "                    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "                    lower=True,                     # lowercase text\n",
    "                    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "                    no_urls=False,                  # replace all URLs with a special token\n",
    "                    no_emails=False,                # replace all email addresses with a special token\n",
    "                    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "                    no_numbers=False,               # replace all numbers with a special token\n",
    "                    no_digits=False,                # replace all digits with a special token\n",
    "                    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "                    no_punct=False,                 # remove punctuations\n",
    "                    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "                    replace_with_url=\"<URL>\",\n",
    "                    replace_with_email=\"<EMAIL>\",\n",
    "                    replace_with_phone_number=\"<PHONE>\",\n",
    "                    replace_with_number=\"<NUMBER>\",\n",
    "                    replace_with_digit=\"0\",\n",
    "                    replace_with_currency_symbol=\"<CUR>\",\n",
    "                    lang=\"en\"                       # set to 'de' for German special handling\n",
    "          )\n",
    "\n",
    "with open(\"../../datasets/c4200m_sample.tsv\", \"r\") as inpf:\n",
    "    texts = [{\"text\":clean_input(line.split(\"\\t\")[0])} for line in inpf][1:10000]\n",
    "'''\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\",\n",
    "                        max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "\n",
    "random_val_per_token = torch.rand(inputs.input_ids.shape)\n",
    "random_selected_mask = random_val_per_token < 0.15\n",
    "\n",
    "not_special_tokens = (inputs.input_ids != 101) *\\\n",
    "                        (inputs.input_ids != 102) *\\\n",
    "                            (inputs.input_ids != 0)\n",
    "\n",
    "masked_tokens = random_selected_mask * not_special_tokens\n",
    "masked_sentences = torch.where(masked_tokens > 0, 103, inputs.input_ids)\n",
    "inputs.input_ids = masked_sentences\n",
    "\n",
    "class C4SentencesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "c4_dataset = C4SentencesDataset(inputs)\n",
    "c4_dataloader = torch.utils.data.DataLoader(c4_dataset, batch_size=32, shuffle=True)\n",
    "'''\n",
    "c4_huggingface_dataset = Dataset.from_list(texts)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(c4_huggingface_dataset))\n",
    "print(type(imdb_dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[23]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = c4_huggingface_dataset.shuffle(seed=42).select(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> Text: the screenings/consultations of the um physicians clinic, 6700 west loop south, suite 11, 20minutes, is in painless, and can be schedaled to calling 713-500-vein (3846).'\n",
      "\n",
      "'>>> Text: back analysis to rock model covering their underground roadways among coal mine based on black hole algorithm.'\n",
      "\n",
      "'>>> Text: draw two alomondith eyeing near the middle of saitama's head.'\n"
     ]
    }
   ],
   "source": [
    "for row in sample:\n",
    "    print(f\"\\n'>>> Text: {row['text']}'\")\n",
    "    #print(f\"'>>> Label: {row['label']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[24]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use batched=True to activate fast multithreading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2330e3363e044c4bda1878fba0a285f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 9999\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = c4_huggingface_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\"]#, \"label\"]\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[25]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing produces a list of lists for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_samples = tokenized_datasets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 19'\n",
      "'>>> Review 1 length: 38'\n",
      "'>>> Review 2 length: 14'\n"
     ]
    }
   ],
   "source": [
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[29]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Concatenated reviews length: 71'\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 128\n",
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")\n",
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 71'\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[30]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "            k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f8890541b84df98f610b3571c05316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2432\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[31]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'word_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m samples \u001b[38;5;241m=\u001b[39m [lm_datasets[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples:\n\u001b[0;32m----> 4\u001b[0m     _ \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'word_ids'"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "samples = [lm_datasets[i] for i in range(10)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] home \" phrase and idiom dictionary \" how does put your [MASK] foot forward here? [SEP] [CLS] [MASK] post - holder would be an integral part of extra - [MASK]rricular life at pocklington [MASK] the [MASK] [MASK] develop student's leadership's skill cutler good an character [MASK] [SEP] [CLS] [MASK] all instructions made by [MASK] physician to your particular condition. [SEP] [CLS] members [MASK] [MASK] firm actively participated [MASK] development of this foreign policy guide. [SEP] [CLS] if you would be basing in local area and [MASK] require more information or request [MASK] for new [MASK]ter installation please contact our office [MASK] send us an enquiry. [SEP] [CLS] [MASK] @ e [MASK]'\n",
      "\n",
      "'>>> ##galan : that new [MASK] delongmusic @ kflay track is a red [MASK] yellow jam. [SEP] [CLS] the commission meeting is open [MASK] the public and anyone judas wishes to hear any candidates will has an opportunity to speak. [SEP] [CLS] when should i use canvas stretcher [MASK] - brace? [SEP] [CLS] the study was published [MASK]. 15 in the journal a jama network open meeting. [SEP] [CLS] [MASK]. 5 [MASK] injunctive relief. ) the [MASK]going provisions haley this section 13 [MASK] not apply to any legal action taken [MASK] gigaom to seek [MASK] injunction or other equitable relief in connection with any loss, cost, or'\n",
      "\n",
      "'>>> damage ( or any potential [MASK] [MASK] cost [MASK] or damage ) relating [MASK] the services [MASK] [MASK] con [MASK] and submissions and [MASK] or [MASK] gigao [MASK] air's intellectual property [MASK] ( including such [MASK]ao [MASK] may may be in dispute ), gigaom's operations, and / or gigaom'[MASK]. [SEP] [CLS] the control element attributes specify that the control of typemicrosoft. windows. controls. calendar ( the full control type name including namespace [MASK] be specified ) is mappedto the test object class mywpfcalendar. [SEP] [CLS] information about bid control & removal services [MASK] the metro phoenix [MASK]..'\n",
      "\n",
      "'>>> scottsdale, sun city, sun city west, surprise az, tempe, tolleson [MASK] waddell, rodent control pirtleville az ant the exterminator vernon a z [MASK]rch [MASK] history [MASK] over 351 [MASK] [MASK] pages on [MASK] internet. [SEP] [CLS] just for interest sake.. the photo does'nt proram [MASK] but outline is done with a belton / redblack.. if ya get the chance [MASK] try it, it's [MASK] crazy colour... it'chorus like red.. but black [MASK] [SEP] [CLS] minimum contract term ( of 3 months. [SEP] [CLS] kick off in'\n",
      "\n",
      "'>>> 2012 / [MASK] nearly here. [SEP] [CLS] [MASK] often willrra the benefi ts of increased us transparency in online shop time [MASK] [SEP] [CLS] will host at club los logartso, [MASK] col april 14 [MASK] 19. [SEP] [CLS] keeping your project on [MASK] programme and on a budget is our main goal and it is [MASK] best way for us to [MASK] achieve this by being quick and accurate with developing your tmp. [SEP] [CLS] the library will host an artist reception with [MASK] bruegger of [MASK] br [MASK]gger photography on wednesday, [MASK] 6 at 5 [MASK]. m. be sure [MASK] [MASK] in [MASK] check out her images in the month of'\n",
      "\n",
      "'>>> [MASK]. [SEP] [CLS] many business owners use a meter because they do their own shipping to put a leg [MASK] be with be promos like same - day or free shipping [MASK] adding a personal service touch when sending off products such as women. [SEP] [CLS] previous post : of amazing iphone dock. [SEP] [CLS] great addition to diy skin care scandal body butters balms [MASK] creams, soaps and more [MASK] [SEP] [CLS] [MASK] can ( either feed the raging little beasties ) left ind [MASK]ured to these pets, [MASK] we can [MASK] ourselves from [MASK] and live with [MASK] more ease. [SEP] [CLS] try free demo before you bought 70 - 123.'\n",
      "\n",
      "'>>> [SEP] [CLS] have [MASK] answer for jon t [MASK] [SEP] [CLS] migration from demon internet ( yes really [MASK] [MASK]! ) to e2020media managed fibre broad - band. [SEP] [CLS] tapper began the conversation by showing dread [MASK] transgender celebrity [MASK] caitlyn [MASK]ner using the women's infection at trump tower and calling cruz out [MASK] his transphobic [MASK]. [SEP] [CLS] [MASK]se ol [MASK] : so would you make a gain over [MASK] percent? [SEP] [CLS] [MASK] sessions every wednesday if youenko 50 + you sail receive $ 5 off any package that using [MASK] [MASK] passport card. [SEP] [CLS] chapter 129 erie shores on. [SEP] [CLS] authorities in pakistan says'\n",
      "\n",
      "'>>> a bomb that [MASK] [MASK] police [MASK] in northwestern pakistan had killed as [MASK] as [MASK] people on january 19th who wounded [MASK]. [SEP] [CLS] keller williams huntsville al ashleigh green keller hates [MASK] ( assistant? ) al agents. [SEP] [CLS] must possess a bachelor's degree with a minimum of second class [MASK] social sciences, procurement & supply chain management, human resources, administration [MASK] banking & finance or accounting, mechanical, electrical or chemical [MASK] or other areas. [SEP] [CLS] from flavorful ethnic sausages to [MASK] healthy [MASK] ta [MASK]er, and better - [MASK] - you chickens, burgers, meatballs and patties, atk foods is a high'\n",
      "\n",
      "'>>> quality manufacturer that is able [MASK] get it right'every time [MASK] s. [SEP] [CLS] please [MASK] right [MASK] disable your username and password, in our sole discretion without [MASK] notice. [SEP] [CLS] there is many divorce attorneys to choose from in minnesota. however, [MASK] is minneapolis divorce lawyer for business barbara who has the business [MASK] real estate background to [MASK] you with complex financial [MASK] that may go up comparing to your divorce [MASK] [SEP] [CLS] i laid [MASK] pieces which inside - out over ottoman and than pince to pinned [MASK] [SEP] [CLS], wooden words for wall cafe wooden sign wood words home kitchen restaurant [MASK] coffee [MASK] [MASK] scsi [MASK]ipt wall'\n",
      "\n",
      "'>>> decoration any color custom [MASK] design gift [MASK] wooden woords wall. [SEP] [CLS] we were raised 550 for the severn freewheel [MASK] ( last [MASK] by 500 ). [SEP] [CLS] umma bubble in mac world aids fund though! [SEP] [CLS] [MASK] of no one else alter to continue to be do it [MASK]. [SEP] [CLS] why you not take advantage of my frei 20 minutes damaging consultation. [SEP] [CLS] bake [MASK] porn from rapunzl'[MASK] tower. [SEP] [CLS] a related book what [MASK] name of'islam for young girls : harassed 1'is also [MASK]. [SEP] [CLS] like many [MASK] his [MASK], though, [MASK]. tauke [MASK]'\n"
     ]
    }
   ],
   "source": [
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[32]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwm_probability = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "    return default_data_collator(features)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[36]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 2_000\n",
    "test_size = int(0.1 * train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_dataset = lm_datasets.train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-imdb\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    # fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[38]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[39]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 01:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 61.28\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[40]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
